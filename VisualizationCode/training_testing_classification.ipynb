{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the detailed classification pipeline.\n",
    "\n",
    "- **Author**: Benkirane Ismail\n",
    "- **Email**: [ibenkirane@mgb.org](mailto:ibenkirane@mgb.org)\n",
    "- **Version**: 1.0.0\n",
    "- **Date**: 2023-10-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import CLASSIFIER,  UTILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities = UTILITIES()\n",
    "classifier = CLASSIFIER()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_csv('../computed_features/all_features.csv')\n",
    "stand_features = pd.read_csv('../computed_features/stand_features.csv')\n",
    "\n",
    "groups = {\n",
    "    'Cluster 1' : [1003, 1007, 1013, 1015, 1020, 1024, 1026],\n",
    "    'Cluster 2' : [1001, 1031, 1032, 1037, 1039],\n",
    "    'Cluster 3' : [1008, 1017, 1022, 1025, 1033, 1040, 1041, 1042],\n",
    "    'All Subjects': [1001, 1003, 1007, 1008, 1013, 1015, 1017, 1020, 1022, 1024, 1025, 1026, 1031, 1032, 1033, 1037, 1039, 1040, 1041]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Express Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_performances = classifier.get_classification_performances(stand_features, groups, augment_data=False, feature_selection=True, nb_features=15, reduce_dim=True, verbose=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 'All Emotions'\n",
    "group = 'All Subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, selected_features = classifier.get_classification_sets(stand_features, objective, groups[group], augment_data=False, feature_selection=True, nb_features=136, reduce_dim=True) # 'Positive vs Negative' 'Neutral vs Non-Neutral' 'Shame vs Others' 'All Emotions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_params = {'n_estimators': 50, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_split': 3, 'criterion': 'gini'}\n",
    "\n",
    "rf_model = RandomForestClassifier(**best_rf_params, random_state=42)\n",
    "rf_model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(np.argmax(y_test, axis=1), rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_params = {'C': 1000, 'kernel': 'rbf', 'gamma': 'scale'}\n",
    "\n",
    "svm_model = SVC(**best_svm_params, probability=True, random_state=42)\n",
    "svm_model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(np.argmax(y_test, axis=1), svm_predictions)\n",
    "\n",
    "print(f\"SVM Accuracy: {svm_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=5,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=1,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',  # or 'multi:softprob' for multiclass and set num_class\n",
    "    reg_alpha=0.005,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(np.argmax(y_test, axis=1), xgb_predictions)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=6),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ada_model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "ada_predictions = ada_model.predict(X_test)\n",
    "ada_accuracy = accuracy_score(np.argmax(y_test, axis=1), ada_predictions)\n",
    "\n",
    "print(f\"AdaBoost Accuracy: {ada_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [('rf', rf_model), ('xgb', xgb_model)] \n",
    "meta_model = GradientBoostingClassifier() \n",
    "\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "stacking_model.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "stacking_predictions = stacking_model.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(np.argmax(y_test, axis=1), stacking_predictions)\n",
    "print(f\"Adjusted Stacking Ensemble Accuracy: {stacking_accuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_extended = VotingClassifier(\n",
    "    estimators=[('rf', rf_model), ('svm', svm_model), ('xgb', xgb_model), ('ada', ada_model)],\n",
    "    voting='soft'  # or 'hard'\n",
    ")\n",
    "\n",
    "voting_clf_extended.fit(X_train, np.argmax(y_train, axis=1))\n",
    "\n",
    "voting_predictions_extended = voting_clf_extended.predict(X_test)\n",
    "voting_accuracy_extended = accuracy_score(np.argmax(y_test, axis=1), voting_predictions_extended)\n",
    "print(f\"Extended Voting Classifier Accuracy: {voting_accuracy_extended * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
