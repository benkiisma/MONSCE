{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the detailed correlation extraction and analysis.\n",
    "\n",
    "- **Author**: Benkirane Ismail\n",
    "- **Email**: [ibenkirane@mgb.org](mailto:ibenkirane@mgb.org)\n",
    "- **Version**: 1.0.0\n",
    "- **Date**: 2023-10-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import UTILITIES, CORRELATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_measurement = ['Empatica', 'Audio', 'FaceReader', 'GoPro']\n",
    "# desired_measurement = 'Empatica'\n",
    "save = True\n",
    "\n",
    "groups = {\n",
    "    'Cluster 1' : [1003, 1007, 1013, 1015, 1020, 1024, 1026],\n",
    "    'Cluster 2' : [1001, 1031, 1032, 1037, 1039],\n",
    "    'Cluster 3' : [1008, 1017, 1022, 1025, 1033, 1040, 1041, 1042],\n",
    "    'All Subjects': [1001, 1003, 1007, 1008, 1013, 1015, 1017, 1020, 1022, 1024, 1025, 1026, 1031, 1032, 1033, 1037, 1039, 1040, 1041]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities = UTILITIES()\n",
    "correlation = CORRELATION(desired_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Express Correlation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    correlation.save_all_correlation_results(desired_measurement=desired_measurement, subject_groups= groups, include_pairs=True, select_features=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(desired_measurement, str):\n",
    "    all_features = pd.read_csv(f'../computed_features/{desired_measurement}/all_features_windows.csv')\n",
    "    stand_features = pd.read_csv(f'../computed_features/{desired_measurement}/stand_features_windows.csv')\n",
    "else:\n",
    "    all_features = pd.read_csv(f'../computed_features/all_features_windows.csv')\n",
    "    stand_features = pd.read_csv(f'../computed_features/stand_features_windows.csv')\n",
    "\n",
    "features_names = utilities.get_feature_names(all_features, desired_measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_grouping = utilities.group_features_by_label(stand_features, windows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in features_grouping.keys():\n",
    "    for row in range(len(features_grouping[emotion])):\n",
    "        features = features_grouping[emotion].iloc[row].index\n",
    "        for feature in features:\n",
    "            if feature != 'label':\n",
    "                basic = len(features_grouping[emotion].iloc[row][features[1]])\n",
    "                if basic != len(features_grouping[emotion].iloc[row][feature]):\n",
    "                    print(emotion, row, feature, basic, len(features_grouping[emotion].iloc[row][feature]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrices = correlation.get_discrete_windows_correlation_matrices(features_grouping, features_names, include_pairs=False)\n",
    "features_correlation = correlation.group_correlated_features(corr_matrices, desired_measurement, time_windows = True,save=save)\n",
    "pair_count_across_subjects = correlation.get_pair_count_across_subjects(features_correlation, desired_measurement, ['Good correlation', 'Strong correlation'], group_cat = True, save=save)\n",
    "pair_count_across_emotions = correlation.get_pair_count_across_emotions(features_correlation, desired_measurement, ['Good correlation', 'Strong correlation'], group_cat = True, save=save)\n",
    "correlation_consistency = correlation.get_correlation_consistency(features_correlation, desired_measurement=desired_measurement, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Analysis\\Correlation\\Empatica\\correlation_consistency.json', 'r') as f:\n",
    "    correlation_consistency = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in correlation_consistency.keys():\n",
    "    for emotion_valence in correlation_consistency[pair].keys():\n",
    "        if len(correlation_consistency[pair][emotion_valence]) >= 10:\n",
    "            print(f'The pair {pair} is consistent across {len(correlation_consistency[pair][emotion_valence])} subjects for {emotion_valence} emotions: ', correlation_consistency[pair][emotion_valence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in correlation_consistency.keys():\n",
    "    for emotion_valence in correlation_consistency[pair].keys():\n",
    "        for subject in correlation_consistency[pair][emotion_valence]:\n",
    "            group1 = True\n",
    "            group2 = True\n",
    "\n",
    "            if subject not in groups['Group 1']:\n",
    "                group1 = False\n",
    "            if subject not in groups['Group 2']:\n",
    "                group2 = False\n",
    "        \n",
    "        if group1:\n",
    "            print(f'{pair} is consistent across {len(correlation_consistency[pair][emotion_valence])} subjects for {emotion_valence} emotions in Group 1')\n",
    "        if group2:\n",
    "            print(f'{pair} is consistent across {len(correlation_consistency[pair][emotion_valence])} subjects for {emotion_valence} emotions in Group 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of correlated features per subject and per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in features_correlation.keys():\n",
    "    print(emotion)\n",
    "    for subject_id in features_correlation[emotion].keys():\n",
    "        print(\"     Subject: \", subject_id)\n",
    "        for correlation_type in features_correlation[emotion][subject_id].keys():\n",
    "            print(\"          \", correlation_type, len(features_correlation[emotion][subject_id][correlation_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of correlated features per emotion and per correlation threshold across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in pair_count_across_subjects.keys():\n",
    "    print(emotion)\n",
    "    for correlation_type in pair_count_across_subjects[emotion].keys():\n",
    "        print(\"     \", correlation_type)\n",
    "        print(\"         \", pair_count_across_subjects[emotion][correlation_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of correlated features per subject and per correlation threshold across emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in pair_count_across_emotions.keys():\n",
    "    print(threshold)\n",
    "    for correlation_type in pair_count_across_emotions[threshold].keys():\n",
    "        print(\"     \", correlation_type)\n",
    "        print(\"         \", pair_count_across_emotions[threshold][correlation_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "\n",
    "desired_measurement = 'Empatica'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Good and Strong Correlations per Subject and Per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Correlation/{desired_measurement}/features_correlation.json', 'r') as file:\n",
    "    correlation = json.load(file)\n",
    "correlation.save_correlation_plots_per_subect_per_emotion(correlation, desired_measurement, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Good Correlation per subject across emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Correlation/{desired_measurement}/PairCount/AcrossEmotions/Good_correlation.json', 'r') as file:\n",
    "    correlation = json.load(file)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 12))\n",
    "axs = axs.flatten()  \n",
    "\n",
    "for idx, nb_emotions in enumerate([1,2,3,4]):\n",
    "    d = dict()\n",
    "\n",
    "    for id in correlation.keys():\n",
    "        t = 0\n",
    "        for pair in correlation[id].keys():\n",
    "            for key in correlation[id][pair].keys():\n",
    "                if correlation[id][pair][key] == nb_emotions:\n",
    "                    t += 1\n",
    "        d[id] = t\n",
    "\n",
    "    ax = axs[idx]\n",
    "    bars = ax.bar(d.keys(), d.values(), color='#DC143C')\n",
    "    ax.set_xlabel('Subject ID', fontsize=12)\n",
    "    ax.set_ylabel('Number of correlated pairs', fontsize=12)\n",
    "    ax.set_title(f'Number of correlated pairs present in {nb_emotions} emotions', fontsize=14)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(f'{desired_measurement} - Distribution of Correlation Pair Counts Across Emotions', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Good Correlation per emotion across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_subjects_list = [5, 10, 15, 20]\n",
    "emotions = ['Frustration', 'Pride', 'Joy', 'Shame']\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 12))\n",
    "axs = axs.flatten() \n",
    "\n",
    "for idx, nb_subjects in enumerate(nb_subjects_list):\n",
    "    d = dict()\n",
    "    for emotion in emotions:\n",
    "        with open(f'Correlation/{desired_measurement}/PairCount/AcrossSubjects/{emotion}/Good_correlation.json', 'r') as file:\n",
    "            correlation = json.load(file)\n",
    "        t = 0\n",
    "        for pair in correlation.keys():\n",
    "            for key in correlation[pair].keys():\n",
    "                if correlation[pair][key] >= nb_subjects:            \n",
    "                    t += 1\n",
    "\n",
    "        d[emotion] = t\n",
    "\n",
    "    ax = axs[idx]\n",
    "    bars = ax.bar(d.keys(), d.values(), color='#DC143C')\n",
    "    ax.set_xlabel('Emotion', fontsize=12)\n",
    "    ax.set_ylabel('Number of correlated pairs', fontsize=12)\n",
    "    ax.set_title(f'Number of correlated pairs present in at least {nb_subjects} subjects', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(f'{desired_measurement} - Distribution of Correlation Pair Counts Across Subjects', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
